{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fcb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "url = 'https://s3.amazonaws.com/tripdata/2023-citibike-tripdata.zip'\n",
    "chunk_size = 1_000_000\n",
    "station_counter = Counter()\n",
    "\n",
    "# Step 1: Download and read outer ZIP\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "outer_zip = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Step 2: Loop through inner ZIPs\n",
    "inner_zip_names = [f for f in outer_zip.namelist() if f.endswith('.zip')]\n",
    "\n",
    "print(f\"Found {len(inner_zip_names)} monthly zip files.\")\n",
    "\n",
    "# First pass — count top 3 stations\n",
    "for inner_name in inner_zip_names:\n",
    "    print(f\"Processing inner ZIP: {inner_name}\")\n",
    "    with outer_zip.open(inner_name) as inner_file:\n",
    "        inner_zip_data = inner_file.read()\n",
    "        with zipfile.ZipFile(io.BytesIO(inner_zip_data)) as inner_zip:\n",
    "            inner_csv_names = [f for f in inner_zip.namelist() if f.endswith('.csv')]\n",
    "            if not inner_csv_names:\n",
    "                continue  # skip if no CSV inside\n",
    "            with inner_zip.open(inner_csv_names[0]) as csv_file:\n",
    "                for chunk in pd.read_csv(csv_file, chunksize=chunk_size, low_memory=False,\n",
    "                                         dtype={'start_station_id': str, 'end_station_id': str}):\n",
    "                    if 'start_station_name' in chunk.columns:\n",
    "                        station_counter.update(chunk['start_station_name'].dropna())\n",
    "\n",
    "# Get top 3\n",
    "top3_stations = [station for station, _ in station_counter.most_common(3)]\n",
    "print(\"\\nTop 3 Start Stations:\")\n",
    "for station in top3_stations:\n",
    "    print(f\"- {station}\")\n",
    "\n",
    "# Second pass — filter and write matching rows\n",
    "output_file = 'top3_stations_output.csv'\n",
    "is_first_chunk = True\n",
    "\n",
    "for inner_name in inner_zip_names:\n",
    "    print(f\"Filtering rows in: {inner_name}\")\n",
    "    with outer_zip.open(inner_name) as inner_file:\n",
    "        inner_zip_data = inner_file.read()\n",
    "        with zipfile.ZipFile(io.BytesIO(inner_zip_data)) as inner_zip:\n",
    "            inner_csv_names = [f for f in inner_zip.namelist() if f.endswith('.csv')]\n",
    "            if not inner_csv_names:\n",
    "                continue\n",
    "            with inner_zip.open(inner_csv_names[0]) as csv_file:\n",
    "                for chunk in pd.read_csv(csv_file, chunksize=chunk_size, low_memory=False,\n",
    "                                         dtype={'start_station_id': str, 'end_station_id': str}):\n",
    "                    if 'start_station_name' not in chunk.columns:\n",
    "                        continue\n",
    "                    filtered = chunk[chunk['start_station_name'].isin(top3_stations)]\n",
    "                    if not filtered.empty:\n",
    "                        filtered.to_csv(output_file, mode='w' if is_first_chunk else 'a',\n",
    "                                        index=False, header=is_first_chunk)\n",
    "                        is_first_chunk = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd5860-ab52-48b7-87f6-8fdefbf3f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned dataset: 366,225 rows × 17 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load CSV\n",
    "df = pd.read_csv(\"top3_stations_output.csv\")  # Replace with your actual filename\n",
    "\n",
    "# 2. Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# 3. Parse datetime columns\n",
    "df['started_at'] = pd.to_datetime(df['started_at'], errors='coerce')\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'], errors='coerce')\n",
    "\n",
    "# 4. Drop rows with invalid/missing datetime\n",
    "df = df.dropna(subset=['started_at', 'ended_at'])\n",
    "\n",
    "# 5. Drop rows with critical missing values\n",
    "critical_cols = ['ride_id', 'rideable_type', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual']\n",
    "df = df.dropna(subset=critical_cols)\n",
    "\n",
    "# 6. Fill optional missing values\n",
    "df['start_station_name'] = df['start_station_name'].fillna('Unknown')\n",
    "df['end_station_name'] = df['end_station_name'].fillna('Unknown')\n",
    "df['start_station_id'] = df['start_station_id'].fillna('-1')\n",
    "df['end_station_id'] = df['end_station_id'].fillna('-1')\n",
    "\n",
    "# 7. Convert data types\n",
    "df['ride_id'] = df['ride_id'].astype(str)\n",
    "df['rideable_type'] = df['rideable_type'].astype('category')\n",
    "df['member_casual'] = df['member_casual'].astype('category')\n",
    "\n",
    "# 8. Create ride duration in minutes\n",
    "df['ride_duration_mins'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60\n",
    "df = df[df['ride_duration_mins'] > 0]  # Remove 0 or negative durations\n",
    "\n",
    "# 9. Optional time-based features\n",
    "df['day_of_week'] = df['started_at'].dt.day_name()\n",
    "df['hour_of_day'] = df['started_at'].dt.hour\n",
    "df['month'] = df['started_at'].dt.month\n",
    "\n",
    "# 10. Final check\n",
    "print(f\"✅ Cleaned dataset: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af43e27-dabc-40b9-8858-0a8f871f25f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0886540-49d6-4c75-b85e-89f478467d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf62ab72-8e24-4c5a-b76b-e3611113158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:56:14,459 INFO: Initializing external client\n",
      "2025-05-10 12:56:14,461 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 12:56:22,147 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228957\n",
      "2025-05-10 12:56:22,713 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 12:56:22,719 INFO: Initializing external client\n",
      "2025-05-10 12:56:22,720 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 12:56:23,847 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228957\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1228957/fs/1213523/fg/1458530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 366225/366225 | Elapsed Time: 00:51 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citi_bike_trips_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1228957/jobs/named/citi_bike_trips_1_offline_fg_materialization/executions\n",
      "2025-05-10 12:57:31,086 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-10 12:57:34,179 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-10 12:59:28,984 INFO: Waiting for execution to finish. Current state: FINISHED. Final status: SUCCEEDED\n",
      "2025-05-10 12:59:29,248 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-10 12:59:29,250 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('citi_bike_trips_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import hopsworks\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "project_name = os.getenv(\"HOPSWORKS_PROJECT\")\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    project=project_name,\n",
    "    api_key_value=api_key\n",
    ")\n",
    "\n",
    "# 1. Connect to Hopsworks\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# 2. Define your cleaned DataFrame (assume it's already created)\n",
    "# df = your cleaned Citi Bike DataFrame\n",
    "\n",
    "# 3. Create feature group\n",
    "from hsfs.feature import Feature\n",
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "# Choose primary keys and event time\n",
    "feature_group = fs.get_or_create_feature_group(\n",
    "    name=\"citi_bike_trips\",\n",
    "    version=1,\n",
    "    description=\"Cleaned Citi Bike trip data with time features\",\n",
    "    primary_key=[\"ride_id\"],\n",
    "    event_time=\"started_at\"\n",
    ")\n",
    "\n",
    "# 4. Save the DataFrame into the feature group\n",
    "feature_group.insert(df, write_options={\"wait_for_job\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a417bb-6ef9-4b93-8aca-387da6447863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>ride_duration_mins</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A46D077151843D7B</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-16 10:39:54.386</td>\n",
       "      <td>2023-01-16 10:45:18.005</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>5.393650</td>\n",
       "      <td>Monday</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233875BAED2E02D0</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-12 16:55:30.755</td>\n",
       "      <td>2023-01-12 17:04:03.688</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>8.548883</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8DD222EA1A1B0BC9</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-08 19:32:25.647</td>\n",
       "      <td>2023-01-08 19:42:00.382</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717618</td>\n",
       "      <td>-74.013071</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>9.578917</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58976A4F584F8D28</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-27 20:01:52.897</td>\n",
       "      <td>2023-01-27 20:08:58.118</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>7.087017</td>\n",
       "      <td>Friday</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDD4C1E89A26727C</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-13 18:02:38.160</td>\n",
       "      <td>2023-01-13 18:11:22.139</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>8.732983</td>\n",
       "      <td>Friday</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type              started_at  \\\n",
       "0  A46D077151843D7B   classic_bike 2023-01-16 10:39:54.386   \n",
       "1  233875BAED2E02D0   classic_bike 2023-01-12 16:55:30.755   \n",
       "2  8DD222EA1A1B0BC9  electric_bike 2023-01-08 19:32:25.647   \n",
       "3  58976A4F584F8D28   classic_bike 2023-01-27 20:01:52.897   \n",
       "4  FDD4C1E89A26727C   classic_bike 2023-01-13 18:02:38.160   \n",
       "\n",
       "                 ended_at     start_station_name  start_station_id  \\\n",
       "0 2023-01-16 10:45:18.005  West St & Chambers St           5329.03   \n",
       "1 2023-01-12 17:04:03.688  West St & Chambers St           5329.03   \n",
       "2 2023-01-08 19:42:00.382  West St & Chambers St           5329.03   \n",
       "3 2023-01-27 20:08:58.118  West St & Chambers St           5329.03   \n",
       "4 2023-01-13 18:11:22.139  West St & Chambers St           5329.03   \n",
       "\n",
       "  end_station_name end_station_id  start_lat  start_lng    end_lat    end_lng  \\\n",
       "0   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "1   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "2   West Thames St        5114.06  40.717618 -74.013071  40.708347 -74.017134   \n",
       "3   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "4   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "\n",
       "  member_casual  ride_duration_mins day_of_week  hour_of_day  month  \n",
       "0        member            5.393650      Monday           10      1  \n",
       "1        member            8.548883    Thursday           16      1  \n",
       "2        member            9.578917      Sunday           19      1  \n",
       "3        member            7.087017      Friday           20      1  \n",
       "4        member            8.732983      Friday           18      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8de5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ride_id', 'rideable_type', 'started_at', 'ended_at',\n",
       "       'start_station_name', 'start_station_id', 'end_station_name',\n",
       "       'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng',\n",
       "       'member_casual', 'ride_duration_mins', 'day_of_week', 'hour_of_day',\n",
       "       'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3c1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
