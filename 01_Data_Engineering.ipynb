{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b7f8f9-dffd-4bf9-95a6-ede5fbb4385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted '202301-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202302-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202303-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202304-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202305-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202306-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202307-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202308-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202309-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202310-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202311-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "Extracted '202312-citibike-tripdata.zip' into 'E:/bike_Taxi/2023-citibike-tripdata'\n",
      "All ZIP files extracted into their original directory.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Specify the directory containing the ZIP files\n",
    "target_dir = 'E:/bike_Taxi/2023-citibike-tripdata'  # e.g., r'C:\\Users\\YourName\\Downloads'\n",
    "\n",
    "# Loop through all files in the specified directory\n",
    "for filename in os.listdir(target_dir):\n",
    "    if filename.lower().endswith('.zip'):\n",
    "        zip_path = os.path.join(target_dir, filename)\n",
    "\n",
    "        # Extract contents directly into the same directory\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(target_dir)\n",
    "            print(f\"Extracted '{filename}' into '{target_dir}'\")\n",
    "\n",
    "print(\"All ZIP files extracted into their original directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac5a43-34ba-492b-8945-b0cd0c1e0ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf4406-43ea-458c-b17a-7a4194a93517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95876d0d-2d7c-46ec-b1ce-ff488785fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd955021-f445-4e11-93fb-6e98369ab3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d85d985-03a4-4e17-bea1-05a8452c9c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All CSV files have the same column structure.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing your 40 CSV files\n",
    "folder_path = \"E:/bike_Taxi/2023-citibike-tripdata\"\n",
    "\n",
    "# Get all CSV file names\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Store column headers of each file\n",
    "column_sets = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, nrows=1)  # Only read first row to get columns\n",
    "        column_sets[file] = list(df.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Check if all column sets are the same\n",
    "first_file_columns = list(column_sets.values())[0]\n",
    "\n",
    "inconsistent_files = [\n",
    "    fname for fname, cols in column_sets.items()\n",
    "    if cols != first_file_columns\n",
    "]\n",
    "\n",
    "if inconsistent_files:\n",
    "    print(\"\\n‚ùå Inconsistent columns found in:\")\n",
    "    for file in inconsistent_files:\n",
    "        print(f\"- {file}\")\n",
    "else:\n",
    "    print(\"‚úÖ All CSV files have the same column structure.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4471ad3-81ee-4ce2-a584-ff2ba0f1f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 202301-citibike-tripdata_1.csv\n",
      "Processing: 202301-citibike-tripdata_2.csv\n",
      "Processing: 202302-citibike-tripdata_1.csv\n",
      "Processing: 202302-citibike-tripdata_2.csv\n",
      "Processing: 202303-citibike-tripdata_1.csv\n",
      "Processing: 202303-citibike-tripdata_2.csv\n",
      "Processing: 202303-citibike-tripdata_3.csv\n",
      "Processing: 202304-citibike-tripdata_1.csv\n",
      "Processing: 202304-citibike-tripdata_2.csv\n",
      "Processing: 202304-citibike-tripdata_3.csv\n",
      "Processing: 202305-citibike-tripdata_1.csv\n",
      "Processing: 202305-citibike-tripdata_2.csv\n",
      "Processing: 202305-citibike-tripdata_3.csv\n",
      "Processing: 202305-citibike-tripdata_4.csv\n",
      "Processing: 202306-citibike-tripdata_1.csv\n",
      "Processing: 202306-citibike-tripdata_2.csv\n",
      "Processing: 202306-citibike-tripdata_3.csv\n",
      "Processing: 202306-citibike-tripdata_4.csv\n",
      "Processing: 202307-citibike-tripdata_1.csv\n",
      "Processing: 202307-citibike-tripdata_2.csv\n",
      "Processing: 202307-citibike-tripdata_3.csv\n",
      "Processing: 202307-citibike-tripdata_4.csv\n",
      "Processing: 202308-citibike-tripdata_1.csv\n",
      "Processing: 202308-citibike-tripdata_2.csv\n",
      "Processing: 202308-citibike-tripdata_3.csv\n",
      "Processing: 202308-citibike-tripdata_4.csv\n",
      "Processing: 202309-citibike-tripdata_1.csv\n",
      "Processing: 202309-citibike-tripdata_2.csv\n",
      "Processing: 202309-citibike-tripdata_3.csv\n",
      "Processing: 202309-citibike-tripdata_4.csv\n",
      "Processing: 202310-citibike-tripdata_1.csv\n",
      "Processing: 202310-citibike-tripdata_2.csv\n",
      "Processing: 202310-citibike-tripdata_3.csv\n",
      "Processing: 202310-citibike-tripdata_4.csv\n",
      "Processing: 202311-citibike-tripdata_1.csv\n",
      "Processing: 202311-citibike-tripdata_2.csv\n",
      "Processing: 202311-citibike-tripdata_3.csv\n",
      "Processing: 202312-citibike-tripdata_1.csv\n",
      "Processing: 202312-citibike-tripdata_2.csv\n",
      "Processing: 202312-citibike-tripdata_3.csv\n",
      "‚úÖ All CSVs processed and combined safely without overloading memory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set your folder path here\n",
    "folder_path = \"E:/bike_Taxi/2023-citibike-tripdata\"\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "output_file = os.path.join(folder_path, 'combined_output.csv')\n",
    "\n",
    "chunk_size = 100000  # Read in manageable chunks\n",
    "first_file = True  # To write header only once\n",
    "\n",
    "for f in csv_files:\n",
    "    file_path = os.path.join(folder_path, f)\n",
    "    print(f\"Processing: {f}\")\n",
    "\n",
    "    try:\n",
    "        # Try reading in chunks\n",
    "        for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)):\n",
    "            chunk.to_csv(output_file, mode='a', index=False, header=first_file)\n",
    "            if first_file:\n",
    "                first_file = False  # Only write header for the first chunk\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {f}. Error: {e}\")\n",
    "\n",
    "print(\"‚úÖ All CSVs processed and combined safely without overloading memory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a9f691-f92b-4fe5-ac4b-50a80f655a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìë Columns in the CSV file:\n",
      "['ride_id', 'rideable_type', 'started_at', 'ended_at', 'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"E:/bike_Taxi/2023-citibike-tripdata/combined_output.csv\"\n",
    "\n",
    "# Read only the header\n",
    "columns = pd.read_csv(file_path, nrows=0).columns.tolist()\n",
    "\n",
    "print(\"üìë Columns in the CSV file:\")\n",
    "print(columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3988ff94-35a0-4c49-bbe4-713bcb1ebc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 35107030\n"
     ]
    }
   ],
   "source": [
    "with open(\"E:/bike_Taxi/2023-citibike-tripdata/combined_output.csv\") as f:\n",
    "    row_count = sum(1 for line in f) - 1  # subtract 1 for the header\n",
    "print(f\"Row count: {row_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d41b95-b1ab-4726-beb1-ea800d2247c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Start Stations:\n",
      "- W 21 St & 6 Ave\n",
      "- Broadway & W 58 St\n",
      "- West St & Chambers St\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "file_path = \"E:/bike_Taxi/2023-citibike-tripdata/combined_output.csv\"\n",
    "chunk_size = 1_000_000\n",
    "\n",
    "# First pass ‚Äî count start station frequencies\n",
    "station_counter = Counter()\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size, dtype={'start_station_id': str, 'end_station_id': str}):\n",
    "    station_counter.update(chunk['start_station_name'].dropna())\n",
    "\n",
    "# Get top 3 stations\n",
    "top3_stations = [station for station, _ in station_counter.most_common(3)]\n",
    "print(\"Top 3 Start Stations:\")\n",
    "for station in top3_stations:\n",
    "    print(f\"- {station}\")\n",
    "\n",
    "# Second pass ‚Äî filter only top 3 stations and write output\n",
    "output_file = 'top3_stations_output.csv'\n",
    "is_first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size, dtype={'start_station_id': str, 'end_station_id': str}):\n",
    "    filtered_chunk = chunk[chunk['start_station_name'].isin(top3_stations)]\n",
    "    if not filtered_chunk.empty:\n",
    "        filtered_chunk.to_csv(output_file, mode='w' if is_first_chunk else 'a', index=False, header=is_first_chunk)\n",
    "        is_first_chunk = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d04384-28f5-4b1f-ada5-71ec7af93599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 366490\n"
     ]
    }
   ],
   "source": [
    "with open(\"E:/bike_Taxi/top3_stations_output.csv\") as f:\n",
    "    row_count = sum(1 for line in f) - 1  # subtract 1 for the header\n",
    "print(f\"Row count: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffafba2-f7e9-4468-bb27-55c1bf5e5b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìë Columns in the CSV file:\n",
      "['ride_id', 'rideable_type', 'started_at', 'ended_at', 'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"E:/bike_Taxi/top3_stations_output.csv\"\n",
    "\n",
    "# Read only the header\n",
    "columns = pd.read_csv(file_path, nrows=0).columns.tolist()\n",
    "\n",
    "print(\"üìë Columns in the CSV file:\")\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cdd5860-ab52-48b7-87f6-8fdefbf3f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset: 366,225 rows √ó 17 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load CSV\n",
    "df = pd.read_csv(\"E:/bike_Taxi/top3_stations_output.csv\")  # Replace with your actual filename\n",
    "\n",
    "# 2. Standardize column names\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# 3. Parse datetime columns\n",
    "df['started_at'] = pd.to_datetime(df['started_at'], errors='coerce')\n",
    "df['ended_at'] = pd.to_datetime(df['ended_at'], errors='coerce')\n",
    "\n",
    "# 4. Drop rows with invalid/missing datetime\n",
    "df = df.dropna(subset=['started_at', 'ended_at'])\n",
    "\n",
    "# 5. Drop rows with critical missing values\n",
    "critical_cols = ['ride_id', 'rideable_type', 'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual']\n",
    "df = df.dropna(subset=critical_cols)\n",
    "\n",
    "# 6. Fill optional missing values\n",
    "df['start_station_name'] = df['start_station_name'].fillna('Unknown')\n",
    "df['end_station_name'] = df['end_station_name'].fillna('Unknown')\n",
    "df['start_station_id'] = df['start_station_id'].fillna('-1')\n",
    "df['end_station_id'] = df['end_station_id'].fillna('-1')\n",
    "\n",
    "# 7. Convert data types\n",
    "df['ride_id'] = df['ride_id'].astype(str)\n",
    "df['rideable_type'] = df['rideable_type'].astype('category')\n",
    "df['member_casual'] = df['member_casual'].astype('category')\n",
    "\n",
    "# 8. Create ride duration in minutes\n",
    "df['ride_duration_mins'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60\n",
    "df = df[df['ride_duration_mins'] > 0]  # Remove 0 or negative durations\n",
    "\n",
    "# 9. Optional time-based features\n",
    "df['day_of_week'] = df['started_at'].dt.day_name()\n",
    "df['hour_of_day'] = df['started_at'].dt.hour\n",
    "df['month'] = df['started_at'].dt.month\n",
    "\n",
    "# 10. Final check\n",
    "print(f\"‚úÖ Cleaned dataset: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af43e27-dabc-40b9-8858-0a8f871f25f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0886540-49d6-4c75-b85e-89f478467d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf62ab72-8e24-4c5a-b76b-e3611113158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:56:14,459 INFO: Initializing external client\n",
      "2025-05-10 12:56:14,461 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 12:56:22,147 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228957\n",
      "2025-05-10 12:56:22,713 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 12:56:22,719 INFO: Initializing external client\n",
      "2025-05-10 12:56:22,720 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 12:56:23,847 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228957\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1228957/fs/1213523/fg/1458530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 366225/366225 | Elapsed Time: 00:51 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citi_bike_trips_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1228957/jobs/named/citi_bike_trips_1_offline_fg_materialization/executions\n",
      "2025-05-10 12:57:31,086 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-10 12:57:34,179 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-10 12:59:28,984 INFO: Waiting for execution to finish. Current state: FINISHED. Final status: SUCCEEDED\n",
      "2025-05-10 12:59:29,248 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-10 12:59:29,250 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('citi_bike_trips_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import hopsworks\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "project_name = os.getenv(\"HOPSWORKS_PROJECT\")\n",
    "\n",
    "# Login to Hopsworks\n",
    "project = hopsworks.login(\n",
    "    project=project_name,\n",
    "    api_key_value=api_key\n",
    ")\n",
    "\n",
    "# 1. Connect to Hopsworks\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# 2. Define your cleaned DataFrame (assume it's already created)\n",
    "# df = your cleaned Citi Bike DataFrame\n",
    "\n",
    "# 3. Create feature group\n",
    "from hsfs.feature import Feature\n",
    "from hsfs.feature_group import FeatureGroup\n",
    "\n",
    "# Choose primary keys and event time\n",
    "feature_group = fs.get_or_create_feature_group(\n",
    "    name=\"citi_bike_trips\",\n",
    "    version=1,\n",
    "    description=\"Cleaned Citi Bike trip data with time features\",\n",
    "    primary_key=[\"ride_id\"],\n",
    "    event_time=\"started_at\"\n",
    ")\n",
    "\n",
    "# 4. Save the DataFrame into the feature group\n",
    "feature_group.insert(df, write_options={\"wait_for_job\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a417bb-6ef9-4b93-8aca-387da6447863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>ride_duration_mins</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A46D077151843D7B</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-16 10:39:54.386</td>\n",
       "      <td>2023-01-16 10:45:18.005</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>5.393650</td>\n",
       "      <td>Monday</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233875BAED2E02D0</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-12 16:55:30.755</td>\n",
       "      <td>2023-01-12 17:04:03.688</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>8.548883</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8DD222EA1A1B0BC9</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-08 19:32:25.647</td>\n",
       "      <td>2023-01-08 19:42:00.382</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717618</td>\n",
       "      <td>-74.013071</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>9.578917</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58976A4F584F8D28</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-27 20:01:52.897</td>\n",
       "      <td>2023-01-27 20:08:58.118</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>7.087017</td>\n",
       "      <td>Friday</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDD4C1E89A26727C</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-13 18:02:38.160</td>\n",
       "      <td>2023-01-13 18:11:22.139</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>8.732983</td>\n",
       "      <td>Friday</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type              started_at  \\\n",
       "0  A46D077151843D7B   classic_bike 2023-01-16 10:39:54.386   \n",
       "1  233875BAED2E02D0   classic_bike 2023-01-12 16:55:30.755   \n",
       "2  8DD222EA1A1B0BC9  electric_bike 2023-01-08 19:32:25.647   \n",
       "3  58976A4F584F8D28   classic_bike 2023-01-27 20:01:52.897   \n",
       "4  FDD4C1E89A26727C   classic_bike 2023-01-13 18:02:38.160   \n",
       "\n",
       "                 ended_at     start_station_name  start_station_id  \\\n",
       "0 2023-01-16 10:45:18.005  West St & Chambers St           5329.03   \n",
       "1 2023-01-12 17:04:03.688  West St & Chambers St           5329.03   \n",
       "2 2023-01-08 19:42:00.382  West St & Chambers St           5329.03   \n",
       "3 2023-01-27 20:08:58.118  West St & Chambers St           5329.03   \n",
       "4 2023-01-13 18:11:22.139  West St & Chambers St           5329.03   \n",
       "\n",
       "  end_station_name end_station_id  start_lat  start_lng    end_lat    end_lng  \\\n",
       "0   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "1   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "2   West Thames St        5114.06  40.717618 -74.013071  40.708347 -74.017134   \n",
       "3   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "4   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "\n",
       "  member_casual  ride_duration_mins day_of_week  hour_of_day  month  \n",
       "0        member            5.393650      Monday           10      1  \n",
       "1        member            8.548883    Thursday           16      1  \n",
       "2        member            9.578917      Sunday           19      1  \n",
       "3        member            7.087017      Friday           20      1  \n",
       "4        member            8.732983      Friday           18      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8de5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ride_id', 'rideable_type', 'started_at', 'ended_at',\n",
       "       'start_station_name', 'start_station_id', 'end_station_name',\n",
       "       'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng',\n",
       "       'member_casual', 'ride_duration_mins', 'day_of_week', 'hour_of_day',\n",
       "       'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3c1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
