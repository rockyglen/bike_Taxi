{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd022715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 14:01:23,583 INFO: Initializing external client\n",
      "2025-05-10 14:01:23,584 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 14:01:26,984 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228957\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (4.70s) \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import hopsworks\n",
    "\n",
    "# Load .env (for Hopsworks & DagsHub creds)\n",
    "load_dotenv()\n",
    "\n",
    "# Hopsworks Login\n",
    "project = hopsworks.login(api_key_value=os.getenv(\"HOPSWORKS_API_KEY\"), project=os.getenv(\"HOPSWORKS_PROJECT\"))\n",
    "fs = project.get_feature_store()\n",
    "fg = fs.get_feature_group(name=\"citi_bike_trips\", version=1)  # ‚¨ÖÔ∏è change this\n",
    "df = fg.read()\n",
    "\n",
    "# Convert to hourly\n",
    "df['start_hour'] = pd.to_datetime(df['started_at']).dt.floor('H')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee032025",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df = df.groupby('start_hour').size().reset_index(name='trip_count')\n",
    "hourly_df['hour_of_day'] = hourly_df['start_hour'].dt.hour\n",
    "hourly_df = hourly_df.sort_values('start_hour').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb630a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Baseline MAE: 18.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Baseline_Mean_Per_Hour at: https://rockyglen:91640b3ddca4ff37282e7c57c52747b2e5511bda@dagshub.com/rockyglen/citi_bike_project.mlflow/#/experiments/0/runs/553ed4e598884ceb864b57031847bd15\n",
      "üß™ View experiment at: https://rockyglen:91640b3ddca4ff37282e7c57c52747b2e5511bda@dagshub.com/rockyglen/citi_bike_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "split_idx = int(len(hourly_df) * 0.8)\n",
    "train = hourly_df.iloc[:split_idx]\n",
    "test = hourly_df.iloc[split_idx:]\n",
    "\n",
    "# Predict using hourly mean\n",
    "mean_per_hour = train.groupby('hour_of_day')['trip_count'].mean()\n",
    "test.loc[:, 'predicted'] = test['hour_of_day'].map(mean_per_hour)\n",
    "\n",
    "# MAE\n",
    "baseline_mae = mean_absolute_error(test['trip_count'], test['predicted'])\n",
    "print(f\"üìâ Baseline MAE: {baseline_mae:.2f}\")\n",
    "\n",
    "# Log to DagsHub\n",
    "username = os.getenv(\"DAGSHUB_USERNAME\")\n",
    "token = os.getenv(\"DAGSHUB_TOKEN\")\n",
    "repo = os.getenv(\"DAGSHUB_REPO_NAME\")\n",
    "mlflow.set_tracking_uri(f\"https://{username}:{token}@dagshub.com/{username}/{repo}.mlflow\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Baseline_Mean_Per_Hour\"):\n",
    "    mlflow.log_param(\"model_type\", \"mean_per_hour\")\n",
    "    mlflow.log_param(\"features_used\", \"hour_of_day\")\n",
    "    mlflow.log_metric(\"MAE\", baseline_mae)\n",
    "\n",
    "    mean_per_hour.to_csv(\"mean_hour_lookup.csv\")\n",
    "    mlflow.log_artifact(\"mean_hour_lookup.csv\")\n",
    "    test[['start_hour', 'trip_count', 'predicted']].to_csv(\"baseline_preds.csv\", index=False)\n",
    "    mlflow.log_artifact(\"baseline_preds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "709a4680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5270\n",
      "[LightGBM] [Info] Number of data points in the train set: 6584, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 45.706409\n",
      "üöÄ LightGBM (28 lags) MAE: 8.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/10 14:02:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run LightGBM_28_Lags at: https://rockyglen:91640b3ddca4ff37282e7c57c52747b2e5511bda@dagshub.com/rockyglen/citi_bike_project.mlflow/#/experiments/0/runs/f17b01c3b7aa4a0a8a183524c8d4b5cf\n",
      "üß™ View experiment at: https://rockyglen:91640b3ddca4ff37282e7c57c52747b2e5511bda@dagshub.com/rockyglen/citi_bike_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Create lag features\n",
    "for lag in range(1, 29):\n",
    "    hourly_df[f'lag_{lag}'] = hourly_df['trip_count'].shift(lag)\n",
    "hourly_df = hourly_df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Split\n",
    "split_idx = int(len(hourly_df) * 0.8)\n",
    "train = hourly_df.iloc[:split_idx]\n",
    "test = hourly_df.iloc[split_idx:]\n",
    "\n",
    "X_train = train[[f'lag_{i}' for i in range(1, 29)]]\n",
    "y_train = train['trip_count']\n",
    "X_test = test[[f'lag_{i}' for i in range(1, 29)]]\n",
    "y_test = test['trip_count']\n",
    "\n",
    "# Train\n",
    "model = lgb.LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "lag_mae = mean_absolute_error(y_test, preds)\n",
    "print(f\"üöÄ LightGBM (28 lags) MAE: {lag_mae:.2f}\")\n",
    "\n",
    "# Log\n",
    "with mlflow.start_run(run_name=\"LightGBM_28_Lags\"):\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"lags_used\", 28)\n",
    "    mlflow.log_metric(\"MAE\", lag_mae)\n",
    "\n",
    "    mlflow.lightgbm.log_model(model, artifact_path=\"model\")\n",
    "    test[['start_hour', 'trip_count']].assign(predicted=preds).to_csv(\"lgbm_preds.csv\", index=False)\n",
    "    mlflow.log_artifact(\"lgbm_preds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128d982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1885\n",
      "[LightGBM] [Info] Number of data points in the train set: 6584, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 45.706409\n",
      "‚ö° Feature-Reduced MAE: 8.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/10 14:02:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run LightGBM_Feature_Reduced at: https://rockyglen:91640b3ddca4ff37282e7c57c52747b2e5511bda@dagshub.com/rockyglen/citi_bike_project.mlflow/#/experiments/0/runs/5d6ca43fbb504432b45eba06cd53e75e\n",
      "üß™ View experiment at: https://rockyglen:91640b3ddca4ff37282e7c57c52747b2e5511bda@dagshub.com/rockyglen/citi_bike_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from dotenv import load_dotenv\n",
    "import hopsworks\n",
    "\n",
    "# ---------------------\n",
    "# Load environment variables\n",
    "# ---------------------\n",
    "load_dotenv()\n",
    "\n",
    "# ---------------------\n",
    "# Connect to Hopsworks\n",
    "# ---------------------\n",
    "project = hopsworks.login(\n",
    "    api_key_value=os.getenv(\"HOPSWORKS_API_KEY\"),\n",
    "    project=os.getenv(\"HOPSWORKS_PROJECT\")\n",
    ")\n",
    "fs = project.get_feature_store()\n",
    "fg = fs.get_feature_group(name=\"citi_bike_trips\", version=1)\n",
    "df = fg.read()\n",
    "\n",
    "# ---------------------\n",
    "# Aggregate data by hour\n",
    "# ---------------------\n",
    "df['start_hour'] = pd.to_datetime(df['started_at']).dt.floor('H')\n",
    "hourly_df = df.groupby('start_hour').size().reset_index(name='trip_count')\n",
    "hourly_df['hour_of_day'] = hourly_df['start_hour'].dt.hour\n",
    "hourly_df = hourly_df.sort_values('start_hour').reset_index(drop=True)\n",
    "\n",
    "# ---------------------\n",
    "# Baseline Model: Mean per hour-of-day\n",
    "# ---------------------\n",
    "split_idx = int(len(hourly_df) * 0.8)\n",
    "train = hourly_df.iloc[:split_idx]\n",
    "test = hourly_df.iloc[split_idx:]\n",
    "\n",
    "mean_per_hour = train.groupby('hour_of_day')['trip_count'].mean()\n",
    "test.loc[:, 'predicted'] = test['hour_of_day'].map(mean_per_hour)\n",
    "baseline_mae = mean_absolute_error(test['trip_count'], test['predicted'])\n",
    "print(f\"üìâ Baseline MAE: {baseline_mae:.2f}\")\n",
    "\n",
    "# ---------------------\n",
    "# MLflow tracking setup (DagsHub)\n",
    "# ---------------------\n",
    "username = os.getenv(\"DAGSHUB_USERNAME\")\n",
    "token = os.getenv(\"DAGSHUB_TOKEN\")\n",
    "repo = os.getenv(\"DAGSHUB_REPO_NAME\")\n",
    "mlflow.set_tracking_uri(f\"https://{username}:{token}@dagshub.com/{username}/{repo}.mlflow\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Baseline_Mean_Per_Hour\"):\n",
    "    mlflow.log_param(\"model_type\", \"mean_per_hour\")\n",
    "    mlflow.log_param(\"features_used\", \"hour_of_day\")\n",
    "    mlflow.log_metric(\"MAE\", baseline_mae)\n",
    "    mean_per_hour.to_csv(\"mean_hour_lookup.csv\")\n",
    "    mlflow.log_artifact(\"mean_hour_lookup.csv\")\n",
    "    test[['start_hour', 'trip_count', 'predicted']].to_csv(\"baseline_preds.csv\", index=False)\n",
    "    mlflow.log_artifact(\"baseline_preds.csv\")\n",
    "\n",
    "# ---------------------\n",
    "# Full Lag Model (28 lag features)\n",
    "# ---------------------\n",
    "for lag in range(1, 29):\n",
    "    hourly_df[f'lag_{lag}'] = hourly_df['trip_count'].shift(lag)\n",
    "hourly_df = hourly_df.dropna().reset_index(drop=True)\n",
    "\n",
    "split_idx = int(len(hourly_df) * 0.8)\n",
    "train = hourly_df.iloc[:split_idx]\n",
    "test = hourly_df.iloc[split_idx:]\n",
    "\n",
    "X_train = train[[f'lag_{i}' for i in range(1, 29)]]\n",
    "y_train = train['trip_count']\n",
    "X_test = test[[f'lag_{i}' for i in range(1, 29)]]\n",
    "y_test = test['trip_count']\n",
    "\n",
    "model = lgb.LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "lag_mae = mean_absolute_error(y_test, preds)\n",
    "print(f\"üöÄ LightGBM (28 lags) MAE: {lag_mae:.2f}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LightGBM_28_Lags\"):\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"lags_used\", 28)\n",
    "    mlflow.log_metric(\"MAE\", lag_mae)\n",
    "    mlflow.lightgbm.log_model(model, artifact_path=\"model\")\n",
    "    test[['start_hour', 'trip_count']].assign(predicted=preds).to_csv(\"lgbm_preds.csv\", index=False)\n",
    "    mlflow.log_artifact(\"lgbm_preds.csv\")\n",
    "\n",
    "# ---------------------\n",
    "# Feature-Reduced Model (Top 10 lags)\n",
    "# ---------------------\n",
    "importances = model.feature_importances_\n",
    "top10 = [f'lag_{i}' for i, _ in sorted(enumerate(importances, 1), key=lambda x: x[1], reverse=True)[:10]]\n",
    "\n",
    "X_train_red = train[top10]\n",
    "X_test_red = test[top10]\n",
    "\n",
    "model_red = lgb.LGBMRegressor()\n",
    "model_red.fit(X_train_red, y_train)\n",
    "preds_red = model_red.predict(X_test_red)\n",
    "reduced_mae = mean_absolute_error(y_test, preds_red)\n",
    "print(f\"‚ö° Feature-Reduced MAE: {reduced_mae:.2f}\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LightGBM_Feature_Reduced\"):\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    mlflow.log_param(\"features_used\", str(top10))\n",
    "    mlflow.log_metric(\"MAE\", reduced_mae)\n",
    "    mlflow.lightgbm.log_model(model_red, artifact_path=\"model\")\n",
    "    test[['start_hour', 'trip_count']].assign(predicted=preds_red).to_csv(\"reduced_preds.csv\", index=False)\n",
    "    mlflow.log_artifact(\"reduced_preds.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
