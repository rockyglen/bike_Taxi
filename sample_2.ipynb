{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89daa205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting download + extraction...\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202505-citibike-tripdata.zip\n",
      "❌ Not found: https://s3.amazonaws.com/tripdata/202505-citibike-tripdata.zip\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202505-citibike-tripdata.csv.zip\n",
      "❌ Not found: https://s3.amazonaws.com/tripdata/202505-citibike-tripdata.csv.zip\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202504-citibike-tripdata.zip\n",
      "✅ Downloaded: 202504-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_4.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202503-citibike-tripdata.zip\n",
      "❌ Not found: https://s3.amazonaws.com/tripdata/202503-citibike-tripdata.zip\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202503-citibike-tripdata.csv.zip\n",
      "✅ Downloaded: 202503-citibike-tripdata.csv.zip\n",
      "📁 Extracting CSV: 202503-citibike-tripdata.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202502-citibike-tripdata.zip\n",
      "✅ Downloaded: 202502-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202502-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202502-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202502-citibike-tripdata_1.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202501-citibike-tripdata.zip\n",
      "✅ Downloaded: 202501-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202501-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202501-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202501-citibike-tripdata_2.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202412-citibike-tripdata.zip\n",
      "✅ Downloaded: 202412-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202412-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202412-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202412-citibike-tripdata_2.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202411-citibike-tripdata.zip\n",
      "✅ Downloaded: 202411-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_4.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202410-citibike-tripdata.zip\n",
      "✅ Downloaded: 202410-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_6.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_3.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202409-citibike-tripdata.zip\n",
      "✅ Downloaded: 202409-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_5.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202408-citibike-tripdata.zip\n",
      "✅ Downloaded: 202408-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_4.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202407-citibike-tripdata.zip\n",
      "✅ Downloaded: 202407-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_5.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202406-citibike-tripdata.zip\n",
      "✅ Downloaded: 202406-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_2.csv\n",
      "\n",
      "🔍 Counting top 3 stations...\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_1.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_2.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_3.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_4.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_5.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "🏆 Top 3 Stations: ['W 21 St & 6 Ave', 'Lafayette St & E 8 St', 'University Pl & E 14 St']\n",
      "\n",
      "📤 Writing filtered data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
      "C:\\Users\\glenl\\AppData\\Local\\Temp\\ipykernel_2852\\3309773046.py:85: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_1.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_2.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_3.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_4.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_5.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "✅ Output written to `top3_stations_output.csv`\n",
      "\n",
      "🧹 Cleaning up temp files...\n",
      "✅ Temp folder deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "from io import BytesIO\n",
    "\n",
    "TEMP_FOLDER = \"tripdata_temp\"\n",
    "OUTPUT_FILE = \"top3_stations_output.csv\"\n",
    "CHUNK_SIZE = 500_000\n",
    "\n",
    "def get_last_12_months_est():\n",
    "    eastern = pytz.timezone(\"US/Eastern\")\n",
    "    now_est = datetime.now(eastern)\n",
    "    return [(now_est - relativedelta(months=i)).strftime('%Y%m') for i in range(12)]\n",
    "\n",
    "def download_zip_to_memory(ym):\n",
    "    base_url = \"https://s3.amazonaws.com/tripdata/\"\n",
    "    filenames = [\n",
    "        f\"{ym}-citibike-tripdata.zip\",\n",
    "        f\"{ym}-citibike-tripdata.csv.zip\"\n",
    "    ]\n",
    "    for fname in filenames:\n",
    "        url = base_url + fname\n",
    "        try:\n",
    "            print(f\"🌐 Trying: {url}\")\n",
    "            r = requests.get(url, timeout=20)\n",
    "            if r.status_code == 200:\n",
    "                print(f\"✅ Downloaded: {fname}\")\n",
    "                return BytesIO(r.content)\n",
    "            else:\n",
    "                print(f\"❌ Not found: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error downloading {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_all_csvs(zip_bytes_io, extract_to):\n",
    "    \"\"\"Extracts all .csv files from zip, even if nested zip files or folders.\"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_bytes_io) as zf:\n",
    "            for member in zf.namelist():\n",
    "                if member.endswith('.zip'):\n",
    "                    # Nested zip file: extract, open, extract .csv from it\n",
    "                    nested_zip_data = zf.read(member)\n",
    "                    with zipfile.ZipFile(BytesIO(nested_zip_data)) as nested_zf:\n",
    "                        for nested_member in nested_zf.namelist():\n",
    "                            if nested_member.endswith('.csv'):\n",
    "                                print(f\"📦 Extracting nested CSV: {nested_member}\")\n",
    "                                nested_zf.extract(nested_member, extract_to)\n",
    "                elif member.endswith('.csv'):\n",
    "                    print(f\"📁 Extracting CSV: {member}\")\n",
    "                    zf.extract(member, extract_to)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting zip: {e}\")\n",
    "\n",
    "def flatten_csvs_folder(root_folder):\n",
    "    flat_files = []\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for fname in files:\n",
    "            if fname.endswith(\".csv\"):\n",
    "                full_path = os.path.join(root, fname)\n",
    "                flat_files.append(full_path)\n",
    "    return flat_files\n",
    "\n",
    "def get_top3_station_names(filepaths):\n",
    "    freq = {}\n",
    "    for path in filepaths:\n",
    "        try:\n",
    "            for chunk in pd.read_csv(path, usecols=[\"start_station_name\"], chunksize=CHUNK_SIZE):\n",
    "                chunk = chunk.dropna(subset=[\"start_station_name\"])\n",
    "                for station in chunk[\"start_station_name\"]:\n",
    "                    freq[station] = freq.get(station, 0) + 1\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {path}: {e}\")\n",
    "    top3 = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    return [x[0] for x in top3]\n",
    "\n",
    "def write_top3_data(filepaths, top3, output=OUTPUT_FILE):\n",
    "    first_write = True\n",
    "    for path in filepaths:\n",
    "        try:\n",
    "            for chunk in pd.read_csv(path, chunksize=CHUNK_SIZE):\n",
    "                if \"start_station_name\" not in chunk.columns:\n",
    "                    continue\n",
    "                filtered = chunk[chunk[\"start_station_name\"].isin(top3)]\n",
    "                if not filtered.empty:\n",
    "                    filtered.to_csv(output, index=False, mode='a' if not first_write else 'w', header=first_write)\n",
    "                    first_write = False\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {path}: {e}\")\n",
    "\n",
    "def run_super_pipeline():\n",
    "    if os.path.exists(TEMP_FOLDER):\n",
    "        shutil.rmtree(TEMP_FOLDER)\n",
    "    os.makedirs(TEMP_FOLDER, exist_ok=True)\n",
    "\n",
    "    months = get_last_12_months_est()\n",
    "    print(\"🚀 Starting download + extraction...\")\n",
    "\n",
    "    for ym in months:\n",
    "        zip_mem = download_zip_to_memory(ym)\n",
    "        if zip_mem:\n",
    "            extract_all_csvs(zip_mem, TEMP_FOLDER)\n",
    "\n",
    "    all_csvs = flatten_csvs_folder(TEMP_FOLDER)\n",
    "    if not all_csvs:\n",
    "        print(\"❌ No CSV files found.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n🔍 Counting top 3 stations...\")\n",
    "    top3 = get_top3_station_names(all_csvs)\n",
    "    print(f\"🏆 Top 3 Stations: {top3}\")\n",
    "\n",
    "    print(\"\\n📤 Writing filtered data...\")\n",
    "    write_top3_data(all_csvs, top3)\n",
    "    print(f\"✅ Output written to `{OUTPUT_FILE}`\")\n",
    "\n",
    "    print(\"\\n🧹 Cleaning up temp files...\")\n",
    "    shutil.rmtree(TEMP_FOLDER)\n",
    "    print(\"✅ Temp folder deleted.\")\n",
    "\n",
    "# Run the pipeline\n",
    "run_super_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd01f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe084d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64192fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting download + extraction...\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202504-citibike-tripdata.zip\n",
      "✅ Downloaded: 202504-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202504-citibike-tripdata_4.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202503-citibike-tripdata.zip\n",
      "❌ Not found: https://s3.amazonaws.com/tripdata/202503-citibike-tripdata.zip\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202503-citibike-tripdata.csv.zip\n",
      "✅ Downloaded: 202503-citibike-tripdata.csv.zip\n",
      "📁 Extracting CSV: 202503-citibike-tripdata.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202502-citibike-tripdata.zip\n",
      "✅ Downloaded: 202502-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202502-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202502-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202502-citibike-tripdata_1.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202501-citibike-tripdata.zip\n",
      "✅ Downloaded: 202501-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202501-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202501-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202501-citibike-tripdata_2.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202412-citibike-tripdata.zip\n",
      "✅ Downloaded: 202412-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202412-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202412-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202412-citibike-tripdata_2.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202411-citibike-tripdata.zip\n",
      "✅ Downloaded: 202411-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202411-citibike-tripdata_4.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202410-citibike-tripdata.zip\n",
      "✅ Downloaded: 202410-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_6.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202410-citibike-tripdata/202410-citibike-tripdata_3.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202409-citibike-tripdata.zip\n",
      "✅ Downloaded: 202409-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202409-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: __MACOSX/._202409-citibike-tripdata_5.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202408-citibike-tripdata.zip\n",
      "✅ Downloaded: 202408-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: 202408-citibike-tripdata_4.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202407-citibike-tripdata.zip\n",
      "✅ Downloaded: 202407-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202407-citibike-tripdata_5.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202406-citibike-tripdata.zip\n",
      "✅ Downloaded: 202406-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_5.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202406-citibike-tripdata_2.csv\n",
      "🌐 Trying: https://s3.amazonaws.com/tripdata/202405-citibike-tripdata.zip\n",
      "✅ Downloaded: 202405-citibike-tripdata.zip\n",
      "📁 Extracting CSV: 202405-citibike-tripdata_1.csv\n",
      "📁 Extracting CSV: 202405-citibike-tripdata_2.csv\n",
      "📁 Extracting CSV: 202405-citibike-tripdata_3.csv\n",
      "📁 Extracting CSV: 202405-citibike-tripdata_4.csv\n",
      "📁 Extracting CSV: 202405-citibike-tripdata_5.csv\n",
      "\n",
      "🔍 Counting top 3 stations...\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_1.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_2.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_3.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_4.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_5.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "🏆 Top 3 Stations: ['W 21 St & 6 Ave', 'University Pl & E 14 St', 'Lafayette St & E 8 St']\n",
      "\n",
      "📤 Writing filtered data...\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_1.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_2.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_3.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_4.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "⚠️ Skipping tripdata_temp\\__MACOSX\\._202409-citibike-tripdata_5.csv: 'utf-8' codec can't decode byte 0xb0 in position 45: invalid start byte\n",
      "✅ Output written to `top3_stations_output.csv`\n",
      "\n",
      "🧹 Cleaning up temp files...\n",
      "✅ Temp folder deleted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "from io import BytesIO\n",
    "\n",
    "TEMP_FOLDER = \"tripdata_temp\"\n",
    "OUTPUT_FILE = \"top3_stations_output.csv\"\n",
    "CHUNK_SIZE = 500_000\n",
    "\n",
    "TARGET_COLS = [\n",
    "    \"ride_id\", \"rideable_type\", \"started_at\", \"ended_at\",\n",
    "    \"start_station_name\", \"start_station_id\",\n",
    "    \"end_station_name\", \"end_station_id\",\n",
    "    \"start_lat\", \"start_lng\", \"end_lat\", \"end_lng\",\n",
    "    \"member_casual\"\n",
    "]\n",
    "\n",
    "DTYPES = {\n",
    "    \"ride_id\": str,\n",
    "    \"rideable_type\": str,\n",
    "    \"started_at\": str,\n",
    "    \"ended_at\": str,\n",
    "    \"start_station_name\": str,\n",
    "    \"start_station_id\": str,\n",
    "    \"end_station_name\": str,\n",
    "    \"end_station_id\": str,\n",
    "    \"start_lat\": float,\n",
    "    \"start_lng\": float,\n",
    "    \"end_lat\": float,\n",
    "    \"end_lng\": float,\n",
    "    \"member_casual\": str\n",
    "}\n",
    "\n",
    "def get_last_12_months_est():\n",
    "    eastern = pytz.timezone(\"US/Eastern\")\n",
    "    now_est = datetime.now(eastern)\n",
    "    # subtract 1 extra month to exclude current month\n",
    "    return [(now_est - relativedelta(months=i + 1)).strftime('%Y%m') for i in range(12)]\n",
    "\n",
    "\n",
    "def download_zip_to_memory(ym):\n",
    "    base_url = \"https://s3.amazonaws.com/tripdata/\"\n",
    "    filenames = [\n",
    "        f\"{ym}-citibike-tripdata.zip\",\n",
    "        f\"{ym}-citibike-tripdata.csv.zip\"\n",
    "    ]\n",
    "    for fname in filenames:\n",
    "        url = base_url + fname\n",
    "        try:\n",
    "            print(f\"🌐 Trying: {url}\")\n",
    "            r = requests.get(url, timeout=20)\n",
    "            if r.status_code == 200:\n",
    "                print(f\"✅ Downloaded: {fname}\")\n",
    "                return BytesIO(r.content)\n",
    "            else:\n",
    "                print(f\"❌ Not found: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error downloading {url}: {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_all_csvs(zip_bytes_io, extract_to):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_bytes_io) as zf:\n",
    "            for member in zf.namelist():\n",
    "                if member.endswith('.zip'):\n",
    "                    nested_zip_data = zf.read(member)\n",
    "                    with zipfile.ZipFile(BytesIO(nested_zip_data)) as nested_zf:\n",
    "                        for nested_member in nested_zf.namelist():\n",
    "                            if nested_member.endswith('.csv'):\n",
    "                                print(f\"📦 Extracting nested CSV: {nested_member}\")\n",
    "                                nested_zf.extract(nested_member, extract_to)\n",
    "                elif member.endswith('.csv'):\n",
    "                    print(f\"📁 Extracting CSV: {member}\")\n",
    "                    zf.extract(member, extract_to)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting zip: {e}\")\n",
    "\n",
    "def flatten_csvs_folder(root_folder):\n",
    "    flat_files = []\n",
    "    for root, _, files in os.walk(root_folder):\n",
    "        for fname in files:\n",
    "            if fname.endswith(\".csv\"):\n",
    "                full_path = os.path.join(root, fname)\n",
    "                flat_files.append(full_path)\n",
    "    return flat_files\n",
    "\n",
    "def get_top3_station_names(filepaths):\n",
    "    freq = {}\n",
    "    for path in filepaths:\n",
    "        try:\n",
    "            for chunk in pd.read_csv(path, usecols=[\"start_station_name\"], dtype={\"start_station_name\": str}, chunksize=CHUNK_SIZE):\n",
    "                chunk = chunk.dropna(subset=[\"start_station_name\"])\n",
    "                for station in chunk[\"start_station_name\"]:\n",
    "                    freq[station] = freq.get(station, 0) + 1\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {path}: {e}\")\n",
    "    top3 = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    return [x[0] for x in top3]\n",
    "\n",
    "def write_top3_data(filepaths, top3, output=OUTPUT_FILE):\n",
    "    first_write = True\n",
    "    for path in filepaths:\n",
    "        try:\n",
    "            for chunk in pd.read_csv(path, usecols=TARGET_COLS, dtype=DTYPES, chunksize=CHUNK_SIZE, low_memory=False):\n",
    "                chunk = chunk.dropna(subset=[\"start_station_name\"])\n",
    "                filtered = chunk[chunk[\"start_station_name\"].isin(top3)]\n",
    "                if not filtered.empty:\n",
    "                    filtered.to_csv(output, index=False, mode='a' if not first_write else 'w', header=first_write)\n",
    "                    first_write = False\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {path}: {e}\")\n",
    "\n",
    "def run_super_pipeline():\n",
    "    if os.path.exists(TEMP_FOLDER):\n",
    "        shutil.rmtree(TEMP_FOLDER)\n",
    "    os.makedirs(TEMP_FOLDER, exist_ok=True)\n",
    "\n",
    "    months = get_last_12_months_est()\n",
    "    print(\"🚀 Starting download + extraction...\")\n",
    "\n",
    "    for ym in months:\n",
    "        zip_mem = download_zip_to_memory(ym)\n",
    "        if zip_mem:\n",
    "            extract_all_csvs(zip_mem, TEMP_FOLDER)\n",
    "\n",
    "    all_csvs = flatten_csvs_folder(TEMP_FOLDER)\n",
    "    if not all_csvs:\n",
    "        print(\"❌ No CSV files found.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n🔍 Counting top 3 stations...\")\n",
    "    top3 = get_top3_station_names(all_csvs)\n",
    "    print(f\"🏆 Top 3 Stations: {top3}\")\n",
    "\n",
    "    print(\"\\n📤 Writing filtered data...\")\n",
    "    write_top3_data(all_csvs, top3)\n",
    "    print(f\"✅ Output written to `{OUTPUT_FILE}`\")\n",
    "\n",
    "    print(\"\\n🧹 Cleaning up temp files...\")\n",
    "    shutil.rmtree(TEMP_FOLDER)\n",
    "    print(\"✅ Temp folder deleted.\")\n",
    "\n",
    "# Run the pipeline\n",
    "run_super_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aad9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449111b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9118dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 21:58:06,996 INFO: Initializing external client\n",
      "2025-05-10 21:58:06,996 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-05-10 21:58:09,369 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1228957\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.85s) \n",
      "🔢 Total predicted hours: 1\n",
      "🗓️ Time range: 2025-05-01 00:00:00+00:00 → 2025-05-01 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "project = hopsworks.login(\n",
    "    api_key_value=os.getenv(\"HOPSWORKS_API_KEY\"),\n",
    "    project=os.getenv(\"HOPSWORKS_PROJECT\")\n",
    ")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "pred_fg = fs.get_feature_group(\"citi_bike_predictions\", version=1)\n",
    "pred_df = pred_fg.read()\n",
    "\n",
    "print(\"🔢 Total predicted hours:\", pred_df['target_hour'].nunique())\n",
    "print(\"🗓️ Time range:\", pred_df['target_hour'].min(), \"→\", pred_df['target_hour'].max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
